{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e71527",
   "metadata": {},
   "source": [
    "# Mechanical Failure Risk Model (Baseline + Model Comparison)\n",
    "\n",
    "Goal: build an initial model that predicts the probability of **mechanical failure** after surgery, using:\n",
    "- **Pre-op patient measurements** (things we know before surgery)\n",
    "- **Plan variables** (things the optimizer can change: ALIF/TLIF/XLIF, implants, etc.)\n",
    "\n",
    "Outputs:\n",
    "- A baseline model (logistic regression) that returns a **risk probability**\n",
    "- A comparison against other models (RF, HistGB, XGBoost)\n",
    "- Saved artifacts so Vanja can plug the model into the optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9deff2",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "Load the Excel file into a dataframe and clean up column names.\n",
    "This avoids annoying issues later (extra spaces, line breaks inside column headers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e0979",
   "metadata": {},
   "source": [
    "## 2) Define inputs (features) and output (target)\n",
    "\n",
    "We explicitly choose which columns the model is allowed to use:\n",
    "\n",
    "- **Predictors (pre-op):** patient demographics + pre-op alignment / bone quality proxies  \n",
    "- **Plan variables:** surgical “knobs” that the optimizer may change (ALIF/TLIF/XLIF, rods/screws, etc.)\n",
    "\n",
    "Then we build:\n",
    "- `X` = feature table (inputs)\n",
    "- `y` = target label (`mech_fail_last`)\n",
    "and drop any rows where `y` is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cb56b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DATA_PROCESSED,\n\u001b[32m      3\u001b[39m     MECH_FAIL_FEATURES,\n\u001b[32m      4\u001b[39m     MECH_FAIL_TARGET\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load cleaned data\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.config import (\n",
    "    DATA_PROCESSED,\n",
    "    MECH_FAIL_FEATURES,\n",
    "    MECH_FAIL_TARGET\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load cleaned data\n",
    "df = pd.read_csv(DATA_PROCESSED)\n",
    "\n",
    "# Fix ODI datatype\n",
    "df[\"ODI_preop\"] = pd.to_numeric(df[\"ODI_preop\"], errors=\"coerce\")\n",
    "\n",
    "# Check missing columns\n",
    "missing = set(MECH_FAIL_FEATURES + [MECH_FAIL_TARGET]) - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "# Create X and y\n",
    "X = df[MECH_FAIL_FEATURES].copy()\n",
    "y = df[MECH_FAIL_TARGET].copy()\n",
    "\n",
    "mask = y.notna()\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask].astype(int)\n",
    "\n",
    "print(\"ODI dtype:\", X[\"ODI_preop\"].dtype)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcb581",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Check how many patients have mechanical failure vs no failure.\n",
    "Also check if there are any missing labels (we can’t train on those rows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf790c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = config.MECH_FAIL_TARGET\n",
    "\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"{target} not found in dataframe\")\n",
    "\n",
    "print(df[target].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2defa48",
   "metadata": {},
   "source": [
    "## 3) Baseline model: logistic regression (with cross-validation)\n",
    "\n",
    "Start with a simple baseline: logistic regression.\n",
    "We set up a pipeline that:\n",
    "- fills missing values\n",
    "- scales numeric columns (helps logreg)\n",
    "- one-hot encodes categorical columns\n",
    "\n",
    "Then we generate **cross-validated probabilities** (each patient is predicted by a model that didn’t train on that patient).\n",
    "This gives us a more honest view of model behavior than training + testing on the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "pipe_logreg = Pipeline([(\"preprocess\", preprocess), (\"model\", model)])\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "probs_logreg = cross_val_predict(pipe_logreg, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
    "probs_logreg[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c288b8",
   "metadata": {},
   "source": [
    "## 4) Evaluate baseline performance\n",
    "\n",
    "Two views of “how good is the model?”:\n",
    "\n",
    "1) **Ranking metrics (no threshold needed)**\n",
    "- ROC-AUC: how well the model separates failures from non-failures overall\n",
    "- PR-AUC (Average Precision): focuses more on identifying failures (useful when failures are less common)\n",
    "\n",
    "2) **Decision metrics (requires a threshold)**\n",
    "We pick a cutoff (default 0.5 here) to convert probabilities into yes/no predictions and compute:\n",
    "- precision, recall, F1\n",
    "- confusion matrix (TP/FP/TN/FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "auc = roc_auc_score(y, probs_logreg)\n",
    "ap  = average_precision_score(y, probs_logreg)\n",
    "\n",
    "preds = (probs_logreg >= 0.5).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "\n",
    "print(\"ROC-AUC:\", auc)\n",
    "print(\"Avg Precision (PR-AUC):\", ap)\n",
    "print(\"Precision:\", precision_score(y, preds, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y, preds, zero_division=0))\n",
    "print(\"F1:\", f1_score(y, preds, zero_division=0))\n",
    "print({\"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d51ab",
   "metadata": {},
   "source": [
    "## 5) Inspect the highest-risk predictions\n",
    "\n",
    "Create a results table with:\n",
    "- predicted failure probability (cross-validated)\n",
    "- true outcome\n",
    "\n",
    "Then sort by predicted risk and look at the top patients.\n",
    "This is an easy way to sanity-check whether high-risk predictions are enriched with actual failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df.loc[mask, :].copy()\n",
    "results[\"pred_fail_prob_cv\"] = probs_logreg\n",
    "\n",
    "results[[\"pred_fail_prob_cv\", \"mech_fail_last\"]].sort_values(\"pred_fail_prob_cv\", ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f91f9",
   "metadata": {},
   "source": [
    "## 6) Threshold tradeoffs \n",
    "\n",
    "The model outputs probabilities, but if we want a yes/no “flag”, we need a threshold.\n",
    "\n",
    "Lower threshold catches more failures but creates more false alarms.  \n",
    "Higher threshold means fewer false alarms but misses more failures.\n",
    "\n",
    "This table helps decide an operating point later (if we ever need a hard cutoff).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    preds_t = (probs_logreg >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, preds_t).ravel()\n",
    "    rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"precision\": precision_score(y, preds_t, zero_division=0),\n",
    "        \"recall\": recall_score(y, preds_t, zero_division=0),\n",
    "        \"f1\": f1_score(y, preds_t, zero_division=0),\n",
    "        \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42dc5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on all data for demonstration (not evaluation)\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "# pick one patient row\n",
    "i = X.index[0]\n",
    "x0 = X.loc[[i]].copy()\n",
    "\n",
    "p_base = pipe_logreg.predict_proba(x0)[:, 1][0]\n",
    "\n",
    "# toggle ALIF if it exists\n",
    "x1 = x0.copy()\n",
    "if \"ALIF\" in x1.columns:\n",
    "    x1[\"ALIF\"] = 1 - int(x1[\"ALIF\"].iloc[0])\n",
    "\n",
    "p_new = pipe_logreg.predict_proba(x1)[:, 1][0]\n",
    "\n",
    "print(\"Base risk:\", p_base)\n",
    "print(\"Toggled ALIF risk:\", p_new)\n",
    "print(\"Change:\", p_new - p_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e305a",
   "metadata": {},
   "source": [
    "## 7) Plan sensitivity test \n",
    "\n",
    "For optimization, it’s not enough to have a good predictor.\n",
    "We also need the risk score to **change** when we change plan variables.\n",
    "\n",
    "Here we do a simple what-if test:\n",
    "- take the same patient row\n",
    "- flip one plan knob like TLIF/ALIF/XLIF\n",
    "- see whether predicted risk changes\n",
    "\n",
    "If the risk doesn’t move, the optimizer can’t use that knob to rank plans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ccc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on all data for demonstration\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "def toggle_and_diff(col, n=10):\n",
    "    diffs = []\n",
    "    idxs = list(X.index)[:n]\n",
    "    for i in idxs:\n",
    "        x0 = X.loc[[i]].copy()\n",
    "        if col not in x0.columns:\n",
    "            continue\n",
    "        if pd.isna(x0[col].iloc[0]):\n",
    "            continue\n",
    "        try:\n",
    "            base = pipe_logreg.predict_proba(x0)[:,1][0]\n",
    "            x1 = x0.copy()\n",
    "            x1[col] = 1 - int(x1[col].iloc[0])  # assumes 0/1\n",
    "            new = pipe_logreg.predict_proba(x1)[:,1][0]\n",
    "            diffs.append(new - base)\n",
    "        except:\n",
    "            pass\n",
    "    return diffs\n",
    "\n",
    "for c in [\"ALIF\", \"TLIF\", \"XLIF\"]:\n",
    "    if c in X.columns:\n",
    "        d = toggle_and_diff(c, n=30)\n",
    "        print(c, \"nonzero diffs:\", sum(abs(x) > 1e-6 for x in d), \"avg abs change:\", np.mean(np.abs(d)) if d else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df873f0d",
   "metadata": {},
   "source": [
    "## 8) Turn the model into a callable risk function\n",
    "\n",
    "This is the interface the optimizer will use:\n",
    "for each candidate plan, it passes in patient features and plan values and gets back a risk probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca65f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fit model on all data (for scoring / optimizer use)\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "FEATURES = list(X.columns)\n",
    "\n",
    "def score_mech_fail(preop_plan_dict: dict) -> float:\n",
    "    \"\"\"\n",
    "    Input: dict with patient preop + plan fields (keys should match FEATURES).\n",
    "    Missing keys are allowed (treated as NaN and imputed).\n",
    "    Output: probability of mechanical failure (0..1).\n",
    "    \"\"\"\n",
    "    row = {c: preop_plan_dict.get(c, np.nan) for c in FEATURES}\n",
    "    X_new = pd.DataFrame([row], columns=FEATURES)\n",
    "    return float(pipe_logreg.predict_proba(X_new)[:, 1][0])\n",
    "\n",
    "#(uses an existing patient row)\n",
    "demo_dict = X.iloc[0].to_dict()\n",
    "print(\"Predicted risk:\", score_mech_fail(demo_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ab04c",
   "metadata": {},
   "source": [
    "## 9) Compare models (baseline vs tree/boosting methods)\n",
    "\n",
    "benchmark multiple models on the same features:\n",
    "- logistic regression\n",
    "- random forest\n",
    "- HistGradientBoosting\n",
    "- XGBoost\n",
    "\n",
    "report:\n",
    "- ROC-AUC and PR-AUC (prediction quality)\n",
    "- plan sensitivity metrics (does risk move when ALIF/TLIF/XLIF is flipped?)\n",
    "\n",
    "The goal is to find:\n",
    "- a strong predictive baseline, and\n",
    "- a model that is usable inside the optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7480647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# XGBoost (now installed)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocessing\n",
    "# -----------------------------\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "\n",
    "preprocess_lr = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"sc\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "preprocess_tree = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "PLAN_VARS = [c for c in [\"ALIF\", \"TLIF\", \"XLIF\"] if c in X.columns]\n",
    "\n",
    "def plan_sensitivity(pipe, X, plan_vars=PLAN_VARS, n=30):\n",
    "    out = {}\n",
    "    idxs = list(X.index)[:min(n, len(X))]\n",
    "    for col in plan_vars:\n",
    "        diffs = []\n",
    "        for i in idxs:\n",
    "            x0 = X.loc[[i]].copy()\n",
    "            v = x0[col].iloc[0]\n",
    "            if pd.isna(v):\n",
    "                continue\n",
    "            try:\n",
    "                vi = int(v)\n",
    "            except:\n",
    "                continue\n",
    "            if vi not in (0, 1):\n",
    "                continue\n",
    "            p0 = float(pipe.predict_proba(x0)[:, 1][0])\n",
    "            x1 = x0.copy()\n",
    "            x1[col] = 1 - vi\n",
    "            p1 = float(pipe.predict_proba(x1)[:, 1][0])\n",
    "            diffs.append(p1 - p0)\n",
    "        diffs = np.array(diffs) if len(diffs) else np.array([])\n",
    "        out[col] = float(np.mean(np.abs(diffs))) if len(diffs) else 0.0\n",
    "    return out\n",
    "\n",
    "def eval_model(name, preprocess, clf):\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "\n",
    "    # Honest cross-validated probabilities\n",
    "    probs = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
    "    roc = roc_auc_score(y, probs)\n",
    "    pr  = average_precision_score(y, probs)\n",
    "\n",
    "    # Fit on all data for plan sensitivity check\n",
    "    pipe.fit(X, y)\n",
    "    sens = plan_sensitivity(pipe, X)\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"roc_auc\": roc,\n",
    "        \"pr_auc\": pr,\n",
    "        **{f\"{k}_avg_abs_change\": v for k, v in sens.items()}\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Models to compare\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "results.append(eval_model(\n",
    "    \"logreg\",\n",
    "    preprocess_lr,\n",
    "    LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "))\n",
    "\n",
    "results.append(eval_model(\n",
    "    \"rf\",\n",
    "    preprocess_tree,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        min_samples_leaf=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "))\n",
    "\n",
    "results.append(eval_model(\n",
    "    \"histgb\",\n",
    "    preprocess_tree,\n",
    "    HistGradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=400\n",
    "    )\n",
    "))\n",
    "\n",
    "# XGBoost (conservative config for small n)\n",
    "results.append(eval_model(\n",
    "    \"xgb\",\n",
    "    preprocess_tree,\n",
    "    XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=2,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        min_child_weight=5,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "))\n",
    "\n",
    "pd.DataFrame(results).sort_values(by=[\"roc_auc\", \"pr_auc\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit final models on full dataset (for saving)\n",
    "pipe_logreg = Pipeline([\n",
    "    (\"prep\", preprocess_lr),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "]).fit(X, y)\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"prep\", preprocess_tree),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=2,\n",
    "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "        min_child_weight=5, random_state=42, eval_metric=\"logloss\"\n",
    "    ))\n",
    "]).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012939f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, sklearn\n",
    "\n",
    "from src import config\n",
    "\n",
    "# Create mech_fail subfolder\n",
    "mech_fail_dir = config.ARTIFACTS_DIR / \"MechanicalFailure\"\n",
    "mech_fail_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = list(X.columns)\n",
    "\n",
    "def save_model(pipe_obj, name):\n",
    "    bundle = {\n",
    "        \"pipe\": pipe_obj,\n",
    "        \"features\": FEATURES,\n",
    "        \"target\": target,\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"model_name\": name,\n",
    "    }\n",
    "    out_path = mech_fail_dir / f\"{name}.joblib\"\n",
    "    joblib.dump(bundle, out_path)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "save_model(pipe_logreg, \"mech_fail_logreg\")\n",
    "save_model(pipe_xgb, \"mech_fail_xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d933c2",
   "metadata": {},
   "source": [
    "# Composite score model (predict post-op composite score from pre-op + plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Jen's composite score calc \n",
    "df[\"gap_category_postop\"] = pd.cut(df[\"gap_score_postop\"], bins=[-np.inf, 2, 6, 13], labels=[\"P\", \"MD\", \"SD\"])\n",
    "\n",
    "def composite_score_calc(df, w1=1, w2=1, w3=1, w4=1, w5=1, w6=1):\n",
    "    weights = [w1, w2, w3, w4, w5, w6]\n",
    "    rel_weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "    gap_score_postop = np.array(df[\"gap_score_postop\"] * 100 / 13)\n",
    "\n",
    "    l1pa_pen = [0 if abs(i) <= 3 else (abs(i) - 3) ** 2 for i in df[\"L1PA_ideal_mismatch_postop\"]]\n",
    "    l1pa_pen = np.array(l1pa_pen) / max(l1pa_pen) * 100 if max(l1pa_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    l4s1_pen = [0 if 35 <= i <= 45 else (35 - i) ** 2 if i < 35 else (i - 45) ** 2 for i in df[\"L4_S1_postop\"]]\n",
    "    l4s1_pen = np.array(l4s1_pen) / max(l4s1_pen) * 100 if max(l4s1_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    t4l1pa_pen = [0 if abs(i) <= 3 else (abs(i) - 3) ** 2 for i in df[\"T4L1PA_ideal_mismatch_postop\"]]\n",
    "    t4l1pa_pen = np.array(t4l1pa_pen) / max(t4l1pa_pen) * 100 if max(t4l1pa_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    ll_ideal = 0.54 * df[\"PI_preop\"] + 27.6\n",
    "    ll_mismatch = df[\"LL_postop\"] - ll_ideal\n",
    "    ll_pen = [0 if abs(i) <= 3 else (abs(i) - 3) ** 2 for i in ll_mismatch]\n",
    "    ll_pen = np.array(ll_pen) / max(ll_pen) * 100 if max(ll_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    gap_category_improvement = []\n",
    "    for i in range(len(df)):\n",
    "        if df[\"gap_category_postop\"].iloc[i] == \"P\" and df[\"gap_category\"].iloc[i] in [\"SD\", \"MD\", \"P\"]:\n",
    "            gap_category_improvement.append(0)\n",
    "        elif df[\"gap_category_postop\"].iloc[i] == \"MD\" and df[\"gap_category\"].iloc[i] == \"SD\":\n",
    "            gap_category_improvement.append(30)\n",
    "        else:\n",
    "            gap_category_improvement.append(100)\n",
    "    gap_category_improvement = np.array(gap_category_improvement)\n",
    "\n",
    "    composite = (\n",
    "        rel_weights[0] * gap_score_postop +\n",
    "        rel_weights[1] * l1pa_pen +\n",
    "        rel_weights[2] * l4s1_pen +\n",
    "        rel_weights[3] * t4l1pa_pen +\n",
    "        rel_weights[4] * ll_pen +\n",
    "        rel_weights[5] * gap_category_improvement\n",
    "    )\n",
    "    return composite\n",
    "\n",
    "df[\"composite_score\"] = composite_score_calc(df)\n",
    "df[\"composite_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab10be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import config\n",
    "\n",
    "PATIENT_FIXED_COLS = config.PATIENT_FIXED_COLS\n",
    "PLAN_COLS = config.PLAN_COLS\n",
    "\n",
    "# Exclude GAP-related predictors for composite regression\n",
    "PREDICTORS = [p for p in PATIENT_FIXED_COLS if \"gap\" not in p]\n",
    "\n",
    "FEATURES_COMP = PREDICTORS + PLAN_COLS\n",
    "\n",
    "y_comp = df[\"composite_score\"].copy()\n",
    "mask_comp = y_comp.notna()\n",
    "\n",
    "X_comp = df.loc[mask_comp, FEATURES_COMP].copy()\n",
    "y_comp = y_comp.loc[mask_comp].astype(float)\n",
    "\n",
    "X_comp.shape, y_comp.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cat_cols_comp = X_comp.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "num_cols_comp = X_comp.select_dtypes(exclude=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "preprocess_tree_comp = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols_comp),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols_comp),\n",
    "])\n",
    "\n",
    "\n",
    "pipe_comp = Pipeline([\n",
    "    (\"prep\", preprocess_tree_comp),\n",
    "    (\"reg\", HistGradientBoostingRegressor(\n",
    "        random_state=42,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=400\n",
    "    ))\n",
    "])\n",
    "\n",
    "pred_comp = cross_val_predict(pipe_comp, X_comp, y_comp, cv=cv_reg)\n",
    "\n",
    "mae  = mean_absolute_error(y_comp, pred_comp)\n",
    "mse  = mean_squared_error(y_comp, pred_comp)\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y_comp, pred_comp)\n",
    "\n",
    "print(\"Composite score CV MAE:\", mae)\n",
    "print(\"Composite score CV RMSE:\", rmse)\n",
    "print(\"Composite score CV R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b401ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp.fit(X_comp, y_comp)\n",
    "FEATURES_COMP = list(X_comp.columns)\n",
    "\n",
    "def score_composite(preop_plan_dict: dict) -> float:\n",
    "    row = {c: preop_plan_dict.get(c, np.nan) for c in FEATURES_COMP}\n",
    "    X_new = pd.DataFrame([row], columns=FEATURES_COMP)\n",
    "    return float(pipe_comp.predict(X_new)[0])\n",
    "\n",
    "demo_dict = X_comp.iloc[0].to_dict()\n",
    "print(\"Predicted composite score:\", score_composite(demo_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d577c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_COMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b356c4",
   "metadata": {},
   "source": [
    "## Mechanical Failure Prediction Model Evaluation\n",
    "Although multiple models were compared (Logistic Regression, Random Forest, HistGradientBoosting, XGBoost), the **Logistic Regression model is used for optimization**, as it demonstrates meaningful responsiveness to surgical plan variables while maintaining comparable predictive performance.\n",
    "\n",
    "The following plots illustrate:\n",
    "\n",
    "- ROC curve (model discrimination ability)\n",
    "- Predicted probability distribution\n",
    "- Feature importance and interpretability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe_logreg = Pipeline([\n",
    "    (\"prep\", preprocess_lr),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "probs_logreg = cross_val_predict(\n",
    "    pipe_logreg, X, y,\n",
    "    cv=cv,\n",
    "    method=\"predict_proba\"\n",
    ")[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y, probs_logreg)\n",
    "roc_auc = roc_auc_score(y, probs_logreg)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.title(f\"ROC Curve - Logistic Regression (AUC={roc_auc:.3f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logreg on full dataset (not CV)\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "# Get transformed feature names\n",
    "feature_names = pipe_logreg.named_steps[\"prep\"].get_feature_names_out()\n",
    "\n",
    "# Get coefficients\n",
    "coefs = pipe_logreg.named_steps[\"clf\"].coef_[0]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coefficient\": coefs,\n",
    "    \"abs_coefficient\": abs(coefs)\n",
    "}).sort_values(\"abs_coefficient\", ascending=False)\n",
    "\n",
    "# Clean feature names\n",
    "coef_df[\"feature\"] = (\n",
    "    coef_df[\"feature\"]\n",
    "    .str.replace(\"num__\", \"\", regex=False)\n",
    "    .str.replace(\"cat__\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "coef_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top = coef_df.head(15).iloc[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.barh(top[\"feature\"], top[\"coefficient\"])\n",
    "plt.title(\"Top Logistic Regression Coefficients\")\n",
    "plt.xlabel(\"Coefficient (Log-Odds Impact)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Fit pipeline fully\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "# Extract preprocessed matrix\n",
    "X_processed = pipe_logreg.named_steps[\"prep\"].transform(X)\n",
    "\n",
    "explainer = shap.LinearExplainer(\n",
    "    pipe_logreg.named_steps[\"clf\"],\n",
    "    X_processed\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_processed)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_processed,\n",
    "    feature_names=feature_names,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_plot = pd.DataFrame({\n",
    "    \"prob\": probs_logreg,\n",
    "    \"actual\": y.values\n",
    "})\n",
    "\n",
    "plt.figure()\n",
    "for label in [0, 1]:\n",
    "    subset = df_plot[df_plot[\"actual\"] == label]\n",
    "    plt.hist(subset[\"prob\"], bins=20, alpha=0.5, density=True)\n",
    "\n",
    "plt.title(\"Predicted Probability Distribution by Outcome\")\n",
    "plt.xlabel(\"Predicted Probability of Mechanical Failure\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend([\"No Failure (0)\", \"Failure (1)\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
