{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e71527",
   "metadata": {},
   "source": [
    "# Mechanical Failure Risk Model (Baseline + Model Comparison)\n",
    "\n",
    "Goal: build an initial model that predicts the probability of **mechanical failure** after surgery, using:\n",
    "- **Pre-op patient measurements** (things we know before surgery)\n",
    "- **Plan variables** (things the optimizer can change: ALIF/TLIF/XLIF, implants, etc.)\n",
    "\n",
    "Outputs:\n",
    "- A baseline model (logistic regression) that returns a **risk probability**\n",
    "- A comparison against other models (RF, HistGB, XGBoost)\n",
    "- Saved artifacts so Vanja can plug the model into the optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9deff2",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "Load the Excel file into a dataframe and clean up column names.\n",
    "This avoids annoying issues later (extra spaces, line breaks inside column headers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56cb56b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 99)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "from src import config\n",
    "\n",
    "df = pd.read_csv(config.DATA_INTERMEDIATE)\n",
    "\n",
    "df.columns = df.columns.astype(str).str.replace(\"\\n\",\" \").str.replace(r\"\\s+\",\" \", regex=True).str.strip()\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcb581",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Check how many patients have mechanical failure vs no failure.\n",
    "Also check if there are any missing labels (we can’t train on those rows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bf790c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mech_fail_last\n",
       "0.0    190\n",
       "1.0     61\n",
       "NaN     26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = config.TARGET_MECH_FAIL\n",
    "df[target].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7cac82",
   "metadata": {},
   "source": [
    "## 2) Define inputs (features) and output (target)\n",
    "\n",
    "We explicitly choose which columns the model is allowed to use:\n",
    "\n",
    "- **Predictors (pre-op):** patient demographics + pre-op alignment / bone quality proxies  \n",
    "- **Plan variables:** surgical “knobs” that the optimizer may change (ALIF/TLIF/XLIF, rods/screws, etc.)\n",
    "\n",
    "Then we build:\n",
    "- `X` = feature table (inputs)\n",
    "- `y` = target label (`mech_fail_last`)\n",
    "and drop any rows where `y` is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32571f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_features: 23\n",
      "Missing (not found in df): []\n",
      "PREDICTORS count: 15\n",
      "PLAN_COLS count: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((251, 23),\n",
       " mech_fail_last\n",
       " 0    190\n",
       " 1     61\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import configuration\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Force reload of config module\n",
    "if 'src.config' in sys.modules:\n",
    "    del sys.modules['src.config']\n",
    "if 'src' in sys.modules:\n",
    "    del sys.modules['src']\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from src import config\n",
    "\n",
    "# Use feature definitions from config\n",
    "PREDICTORS = config.PREDICTORS\n",
    "PLAN_COLS = config.PLAN_COLS\n",
    "target = config.TARGET_MECH_FAIL\n",
    "\n",
    "# Keep only columns that actually exist in the dataframe\n",
    "features = [c for c in (PREDICTORS + PLAN_COLS) if c in df.columns]\n",
    "missing = [c for c in (PREDICTORS + PLAN_COLS) if c not in df.columns]\n",
    "\n",
    "print(\"Using n_features:\", len(features))\n",
    "print(\"Missing (not found in df):\", missing)\n",
    "print(\"PREDICTORS count:\", len(PREDICTORS))\n",
    "print(\"PLAN_COLS count:\", len(PLAN_COLS))\n",
    "\n",
    "# Build X and y\n",
    "X = df[features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# Drop rows with missing target\n",
    "mask = y.notna()\n",
    "X = X.loc[mask].copy()\n",
    "y = y.loc[mask].astype(int)\n",
    "\n",
    "X.shape, y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2defa48",
   "metadata": {},
   "source": [
    "## 3) Baseline model: logistic regression (with cross-validation)\n",
    "\n",
    "Start with a simple baseline: logistic regression.\n",
    "We set up a pipeline that:- fills missing values\n",
    "- scales numeric columns (helps logreg)\n",
    "- one-hot encodes categorical columns\n",
    "\n",
    "Then we generate **cross-validated probabilities** (each patient is predicted by a model that didn’t train on that patient).\n",
    "This gives us a more honest view of model behavior than training + testing on the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f0c14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81286196, 0.16643188, 0.55362524, 0.33481473, 0.5336457 ,\n",
       "       0.3947708 , 0.42186154, 0.39403795, 0.42951646, 0.2352386 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "pipe_logreg = Pipeline([(\"preprocess\", preprocess), (\"model\", model)])\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "probs_logreg = cross_val_predict(pipe_logreg, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
    "probs_logreg[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c288b8",
   "metadata": {},
   "source": [
    "## 4) Evaluate baseline performance\n",
    "\n",
    "Two views of “how good is the model?”:\n",
    "\n",
    "1) **Ranking metrics (no threshold needed)**\n",
    "- ROC-AUC: how well the model separates failures from non-failures overall\n",
    "- PR-AUC (Average Precision): focuses more on identifying failures (useful when failures are less common)\n",
    "\n",
    "2) **Decision metrics (requires a threshold)**\n",
    "We pick a cutoff (default 0.5 here) to convert probabilities into yes/no predictions and compute:\n",
    "- precision, recall, F1\n",
    "- confusion matrix (TP/FP/TN/FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4eb0d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5337359792924935\n",
      "Avg Precision (PR-AUC): 0.27798400207171803\n",
      "Precision: 0.27358490566037735\n",
      "Recall: 0.47540983606557374\n",
      "F1: 0.3473053892215569\n",
      "{'tn': 113, 'fp': 77, 'fn': 32, 'tp': 29}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "auc = roc_auc_score(y, probs_logreg)\n",
    "ap  = average_precision_score(y, probs_logreg)\n",
    "\n",
    "preds = (probs_logreg >= 0.5).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "\n",
    "print(\"ROC-AUC:\", auc)\n",
    "print(\"Avg Precision (PR-AUC):\", ap)\n",
    "print(\"Precision:\", precision_score(y, preds, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y, preds, zero_division=0))\n",
    "print(\"F1:\", f1_score(y, preds, zero_division=0))\n",
    "print({\"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d51ab",
   "metadata": {},
   "source": [
    "## 5) Inspect the highest-risk predictions\n",
    "\n",
    "Create a results table with:\n",
    "- predicted failure probability (cross-validated)\n",
    "- true outcome\n",
    "\n",
    "Then sort by predicted risk and look at the top patients.\n",
    "This is an easy way to sanity-check whether high-risk predictions are enriched with actual failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1623f864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_fail_prob_cv</th>\n",
       "      <th>mech_fail_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.984680</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.918268</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.904956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.895164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.888974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.858031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.855696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.823152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.812862</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.810798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.809113</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.807670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.795418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.782892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.782398</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_fail_prob_cv  mech_fail_last\n",
       "258           0.984680             0.0\n",
       "238           0.918268             1.0\n",
       "136           0.904956             0.0\n",
       "39            0.895164             0.0\n",
       "67            0.888974             0.0\n",
       "220           0.858031             0.0\n",
       "52            0.855696             1.0\n",
       "98            0.823152             0.0\n",
       "0             0.812862             1.0\n",
       "108           0.810798             1.0\n",
       "36            0.809113             0.0\n",
       "200           0.807670             0.0\n",
       "102           0.795418             0.0\n",
       "228           0.782892             0.0\n",
       "79            0.782398             0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = df.loc[mask, :].copy()\n",
    "results[\"pred_fail_prob_cv\"] = probs_logreg\n",
    "\n",
    "results[[\"pred_fail_prob_cv\", \"mech_fail_last\"]].sort_values(\"pred_fail_prob_cv\", ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f91f9",
   "metadata": {},
   "source": [
    "## 6) Threshold tradeoffs \n",
    "\n",
    "The model outputs probabilities, but if we want a yes/no “flag”, we need a threshold.\n",
    "\n",
    "Lower threshold catches more failures but creates more false alarms.  \n",
    "Higher threshold means fewer false alarms but misses more failures.\n",
    "\n",
    "This table helps decide an operating point later (if we ever need a hard cutoff).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e332ec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.253394</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.397163</td>\n",
       "      <td>56</td>\n",
       "      <td>165</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.243523</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>47</td>\n",
       "      <td>146</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>37</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>20</td>\n",
       "      <td>48</td>\n",
       "      <td>142</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>166</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision    recall        f1  tp   fp   tn  fn\n",
       "0        0.2   0.253394  0.918033  0.397163  56  165   25   5\n",
       "1        0.3   0.243523  0.770492  0.370079  47  146   44  14\n",
       "2        0.4   0.251701  0.606557  0.355769  37  110   80  24\n",
       "3        0.5   0.273585  0.475410  0.347305  29   77  113  32\n",
       "4        0.6   0.294118  0.327869  0.310078  20   48  142  41\n",
       "5        0.7   0.294118  0.163934  0.210526  10   24  166  51"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    preds_t = (probs_logreg >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, preds_t).ravel()\n",
    "    rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"precision\": precision_score(y, preds_t, zero_division=0),\n",
    "        \"recall\": recall_score(y, preds_t, zero_division=0),\n",
    "        \"f1\": f1_score(y, preds_t, zero_division=0),\n",
    "        \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c42dc5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base risk: 0.8168100399141661\n",
      "Toggled ALIF risk: 0.8600690752026754\n",
      "Change: 0.04325903528850927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    }
   ],
   "source": [
    "# Fit on all data for demonstration (not evaluation)\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "# pick one patient row\n",
    "i = X.index[0]\n",
    "x0 = X.loc[[i]].copy()\n",
    "\n",
    "p_base = pipe_logreg.predict_proba(x0)[:, 1][0]\n",
    "\n",
    "# toggle ALIF if it exists\n",
    "x1 = x0.copy()\n",
    "if \"ALIF\" in x1.columns:\n",
    "    x1[\"ALIF\"] = 1 - int(x1[\"ALIF\"].iloc[0])\n",
    "\n",
    "p_new = pipe_logreg.predict_proba(x1)[:, 1][0]\n",
    "\n",
    "print(\"Base risk:\", p_base)\n",
    "print(\"Toggled ALIF risk:\", p_new)\n",
    "print(\"Change:\", p_new - p_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e305a",
   "metadata": {},
   "source": [
    "## 7) Plan sensitivity test \n",
    "\n",
    "For optimization, it’s not enough to have a good predictor.\n",
    "We also need the risk score to **change** when we change plan variables.\n",
    "\n",
    "Here we do a simple what-if test:\n",
    "- take the same patient row\n",
    "- flip one plan knob like TLIF/ALIF/XLIF\n",
    "- see whether predicted risk changes\n",
    "\n",
    "If the risk doesn’t move, the optimizer can’t use that knob to rank plans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "297ccc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIF nonzero diffs: 30 avg abs change: 0.06951351807380307\n",
      "TLIF nonzero diffs: 30 avg abs change: 0.4112457439524346\n",
      "XLIF nonzero diffs: 30 avg abs change: 0.1478459436236458\n"
     ]
    }
   ],
   "source": [
    "# Fit on all data for demonstration\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "def toggle_and_diff(col, n=10):\n",
    "    diffs = []\n",
    "    idxs = list(X.index)[:n]\n",
    "    for i in idxs:\n",
    "        x0 = X.loc[[i]].copy()\n",
    "        if col not in x0.columns:\n",
    "            continue\n",
    "        if pd.isna(x0[col].iloc[0]):\n",
    "            continue\n",
    "        try:\n",
    "            base = pipe_logreg.predict_proba(x0)[:,1][0]\n",
    "            x1 = x0.copy()\n",
    "            x1[col] = 1 - int(x1[col].iloc[0])  # assumes 0/1\n",
    "            new = pipe_logreg.predict_proba(x1)[:,1][0]\n",
    "            diffs.append(new - base)\n",
    "        except:\n",
    "            pass\n",
    "    return diffs\n",
    "\n",
    "for c in [\"ALIF\", \"TLIF\", \"XLIF\"]:\n",
    "    if c in X.columns:\n",
    "        d = toggle_and_diff(c, n=30)\n",
    "        print(c, \"nonzero diffs:\", sum(abs(x) > 1e-6 for x in d), \"avg abs change:\", np.mean(np.abs(d)) if d else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df873f0d",
   "metadata": {},
   "source": [
    "## 8) Turn the model into a callable risk function\n",
    "\n",
    "This is the interface the optimizer will use:\n",
    "for each candidate plan, it passes in patient features and plan values and gets back a risk probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ca65f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted risk: 0.8168100399141661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fit model on all data (for scoring / optimizer use)\n",
    "pipe_logreg.fit(X, y)\n",
    "\n",
    "FEATURES = list(X.columns)\n",
    "\n",
    "def score_mech_fail(preop_plan_dict: dict) -> float:\n",
    "    \"\"\"\n",
    "    Input: dict with patient preop + plan fields (keys should match FEATURES).\n",
    "    Missing keys are allowed (treated as NaN and imputed).\n",
    "    Output: probability of mechanical failure (0..1).\n",
    "    \"\"\"\n",
    "    row = {c: preop_plan_dict.get(c, np.nan) for c in FEATURES}\n",
    "    X_new = pd.DataFrame([row], columns=FEATURES)\n",
    "    return float(pipe_logreg.predict_proba(X_new)[:, 1][0])\n",
    "\n",
    "#(uses an existing patient row)\n",
    "demo_dict = X.iloc[0].to_dict()\n",
    "print(\"Predicted risk:\", score_mech_fail(demo_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ab04c",
   "metadata": {},
   "source": [
    "## 9) Compare models (baseline vs tree/boosting methods)\n",
    "\n",
    "benchmark multiple models on the same features:\n",
    "- logistic regression\n",
    "- random forest\n",
    "- HistGradientBoosting\n",
    "- XGBoost\n",
    "\n",
    "report:\n",
    "- ROC-AUC and PR-AUC (prediction quality)\n",
    "- plan sensitivity metrics (does risk move when ALIF/TLIF/XLIF is flipped?)\n",
    "\n",
    "The goal is to find:\n",
    "- a strong predictive baseline, and\n",
    "- a model that is usable inside the optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7480647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>ALIF_avg_abs_change</th>\n",
       "      <th>TLIF_avg_abs_change</th>\n",
       "      <th>XLIF_avg_abs_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.560569</td>\n",
       "      <td>0.303285</td>\n",
       "      <td>0.017377</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.014439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.554616</td>\n",
       "      <td>0.279494</td>\n",
       "      <td>0.048674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.533736</td>\n",
       "      <td>0.277984</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.411246</td>\n",
       "      <td>0.147846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>histgb</td>\n",
       "      <td>0.501122</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>0.039643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model   roc_auc    pr_auc  ALIF_avg_abs_change  TLIF_avg_abs_change  \\\n",
       "1      rf  0.560569  0.303285             0.017377             0.001444   \n",
       "3     xgb  0.554616  0.279494             0.048674             0.000000   \n",
       "0  logreg  0.533736  0.277984             0.069514             0.411246   \n",
       "2  histgb  0.501122  0.253623             0.039643             0.000000   \n",
       "\n",
       "   XLIF_avg_abs_change  \n",
       "1             0.014439  \n",
       "3             0.000000  \n",
       "0             0.147846  \n",
       "2             0.011345  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# XGBoost (now installed)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocessing\n",
    "# -----------------------------\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "preprocess_lr = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                      (\"sc\", StandardScaler())]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "preprocess_tree = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                      (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "PLAN_VARS = [c for c in [\"ALIF\", \"TLIF\", \"XLIF\"] if c in X.columns]\n",
    "\n",
    "def plan_sensitivity(pipe, X, plan_vars=PLAN_VARS, n=30):\n",
    "    out = {}\n",
    "    idxs = list(X.index)[:min(n, len(X))]\n",
    "    for col in plan_vars:\n",
    "        diffs = []\n",
    "        for i in idxs:\n",
    "            x0 = X.loc[[i]].copy()\n",
    "            v = x0[col].iloc[0]\n",
    "            if pd.isna(v):\n",
    "                continue\n",
    "            try:\n",
    "                vi = int(v)\n",
    "            except:\n",
    "                continue\n",
    "            if vi not in (0, 1):\n",
    "                continue\n",
    "            p0 = float(pipe.predict_proba(x0)[:, 1][0])\n",
    "            x1 = x0.copy()\n",
    "            x1[col] = 1 - vi\n",
    "            p1 = float(pipe.predict_proba(x1)[:, 1][0])\n",
    "            diffs.append(p1 - p0)\n",
    "        diffs = np.array(diffs) if len(diffs) else np.array([])\n",
    "        out[col] = float(np.mean(np.abs(diffs))) if len(diffs) else 0.0\n",
    "    return out\n",
    "\n",
    "def eval_model(name, preprocess, clf):\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "\n",
    "    # Honest cross-validated probabilities\n",
    "    probs = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
    "    roc = roc_auc_score(y, probs)\n",
    "    pr  = average_precision_score(y, probs)\n",
    "\n",
    "    # Fit on all data for plan sensitivity check\n",
    "    pipe.fit(X, y)\n",
    "    sens = plan_sensitivity(pipe, X)\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"roc_auc\": roc,\n",
    "        \"pr_auc\": pr,\n",
    "        **{f\"{k}_avg_abs_change\": v for k, v in sens.items()}\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Models to compare\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "results.append(eval_model(\n",
    "    \"logreg\",\n",
    "    preprocess_lr,\n",
    "    LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "))\n",
    "\n",
    "results.append(eval_model(\n",
    "    \"rf\",\n",
    "    preprocess_tree,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        min_samples_leaf=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "))\n",
    "\n",
    "results.append(eval_model(\n",
    "    \"histgb\",\n",
    "    preprocess_tree,\n",
    "    HistGradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=400\n",
    "    )\n",
    "))\n",
    "\n",
    "# XGBoost (conservative config for small n)\n",
    "results.append(eval_model(\n",
    "    \"xgb\",\n",
    "    preprocess_tree,\n",
    "    XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=2,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        min_child_weight=5,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "))\n",
    "\n",
    "pd.DataFrame(results).sort_values(by=[\"roc_auc\", \"pr_auc\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c100e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/vanjaglisic/Library/Caches/pypoetry/virtualenvs/capstone-zWdodsJX-py3.14/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    }
   ],
   "source": [
    "# Refit final models on full dataset (for saving)\n",
    "pipe_logreg = Pipeline([\n",
    "    (\"prep\", preprocess_lr),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "]).fit(X, y)\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"prep\", preprocess_tree),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=2,\n",
    "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "        min_child_weight=5, random_state=42, eval_metric=\"logloss\"\n",
    "    ))\n",
    "]).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "012939f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../artifacts/mech_fail_logreg.joblib\n",
      "Saved: ../artifacts/mech_fail_xgb.joblib\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib, sklearn\n",
    "\n",
    "ARTIFACT_DIR = Path(\"../artifacts\")\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = list(X.columns)\n",
    "\n",
    "def save_model(pipe_obj, name):\n",
    "    bundle = {\n",
    "        \"pipe\": pipe_obj,\n",
    "        \"features\": FEATURES,\n",
    "        \"target\": target,\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"model_name\": name,\n",
    "    }\n",
    "    out_path = ARTIFACT_DIR / f\"{name}.joblib\"\n",
    "    joblib.dump(bundle, out_path)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "save_model(pipe_logreg, \"mech_fail_logreg\")\n",
    "save_model(pipe_xgb, \"mech_fail_xgb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d933c2",
   "metadata": {},
   "source": [
    "# Composite score model (predict post-op composite score from pre-op + plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9674c9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    272.000000\n",
       "mean      18.893925\n",
       "std       13.040111\n",
       "min        0.000000\n",
       "25%        9.174274\n",
       "50%       16.302305\n",
       "75%       29.256139\n",
       "max       57.003920\n",
       "Name: composite_score, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Jen's composite score calc \n",
    "df[\"gap_category_postop\"] = pd.cut(df[\"gap_score_postop\"], bins=[-np.inf, 2, 6, 13], labels=[\"P\", \"MD\", \"SD\"])\n",
    "\n",
    "def composite_score_calc(df, w1=1, w2=1, w3=1, w4=1, w5=1, w6=1):\n",
    "    weights = [w1, w2, w3, w4, w5, w6]\n",
    "    rel_weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "    gap_score_postop = np.array(df[\"gap_score_postop\"] * 100 / 13)\n",
    "\n",
    "    l1pa_pen = [0 if abs(i) <= 3 else (abs(i) - 3) ** 2 for i in df[\"L1PA_ideal_mismatch_postop\"]]\n",
    "    l1pa_pen = np.array(l1pa_pen) / max(l1pa_pen) * 100 if max(l1pa_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    l4s1_pen = [0 if 35 <= i <= 45 else (35 - i) ** 2 if i < 35 else (i - 45) ** 2 for i in df[\"L4_S1_postop\"]]\n",
    "    l4s1_pen = np.array(l4s1_pen) / max(l4s1_pen) * 100 if max(l4s1_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    t4l1pa_pen = [0 if abs(i) <= 3 else (abs(i) - 3) ** 2 for i in df[\"T4L1PA_ideal_mismatch_postop\"]]\n",
    "    t4l1pa_pen = np.array(t4l1pa_pen) / max(t4l1pa_pen) * 100 if max(t4l1pa_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    ll_ideal = 0.54 * df[\"PI_preop\"] + 27.6\n",
    "    ll_mismatch = df[\"LL_postop\"] - ll_ideal\n",
    "    ll_pen = [0 if abs(i) <= 3 else (abs(i) - 3) ** 2 for i in ll_mismatch]\n",
    "    ll_pen = np.array(ll_pen) / max(ll_pen) * 100 if max(ll_pen) > 0 else np.zeros(len(df))\n",
    "\n",
    "    gap_category_improvement = []\n",
    "    for i in range(len(df)):\n",
    "        if df[\"gap_category_postop\"].iloc[i] == \"P\" and df[\"gap_category\"].iloc[i] in [\"SD\", \"MD\", \"P\"]:\n",
    "            gap_category_improvement.append(0)\n",
    "        elif df[\"gap_category_postop\"].iloc[i] == \"MD\" and df[\"gap_category\"].iloc[i] == \"SD\":\n",
    "            gap_category_improvement.append(30)\n",
    "        else:\n",
    "            gap_category_improvement.append(100)\n",
    "    gap_category_improvement = np.array(gap_category_improvement)\n",
    "\n",
    "    composite = (\n",
    "        rel_weights[0] * gap_score_postop +\n",
    "        rel_weights[1] * l1pa_pen +\n",
    "        rel_weights[2] * l4s1_pen +\n",
    "        rel_weights[3] * t4l1pa_pen +\n",
    "        rel_weights[4] * ll_pen +\n",
    "        rel_weights[5] * gap_category_improvement\n",
    "    )\n",
    "    return composite\n",
    "\n",
    "df[\"composite_score\"] = composite_score_calc(df)\n",
    "df[\"composite_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aab10be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((272, 23),\n",
       " count    272.000000\n",
       " mean      18.893925\n",
       " std       13.040111\n",
       " min        0.000000\n",
       " 25%        9.174274\n",
       " 50%       16.302305\n",
       " 75%       29.256139\n",
       " max       57.003920\n",
       " Name: composite_score, dtype: float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_comp = df[\"composite_score\"].copy()\n",
    "\n",
    "mask_comp = y_comp.notna()\n",
    "X_comp = df.loc[mask_comp, features].copy()\n",
    "y_comp = y_comp.loc[mask_comp].astype(float)\n",
    "\n",
    "X_comp.shape, y_comp.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c221e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite score CV MAE: 12.007636039591816\n",
      "Composite score CV RMSE: 14.4667352709713\n",
      "Composite score CV R2: -0.23531605813330514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "pipe_comp = Pipeline([\n",
    "    (\"prep\", preprocess_tree),  # reuse your tree preprocessing\n",
    "    (\"reg\", HistGradientBoostingRegressor(\n",
    "        random_state=42, max_depth=3, learning_rate=0.05, max_iter=400\n",
    "    ))\n",
    "])\n",
    "\n",
    "pred_comp = cross_val_predict(pipe_comp, X_comp, y_comp, cv=cv_reg)\n",
    "\n",
    "mae  = mean_absolute_error(y_comp, pred_comp)\n",
    "mse  = mean_squared_error(y_comp, pred_comp)\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y_comp, pred_comp)\n",
    "\n",
    "print(\"Composite score CV MAE:\", mae)\n",
    "print(\"Composite score CV RMSE:\", rmse)\n",
    "print(\"Composite score CV R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2b401ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted composite score: 11.759351988081727\n"
     ]
    }
   ],
   "source": [
    "pipe_comp.fit(X_comp, y_comp)\n",
    "FEATURES_COMP = list(X_comp.columns)\n",
    "\n",
    "def score_composite(preop_plan_dict: dict) -> float:\n",
    "    row = {c: preop_plan_dict.get(c, np.nan) for c in FEATURES_COMP}\n",
    "    X_new = pd.DataFrame([row], columns=FEATURES_COMP)\n",
    "    return float(pipe_comp.predict(X_new)[0])\n",
    "\n",
    "demo_dict = X_comp.iloc[0].to_dict()\n",
    "print(\"Predicted composite score:\", score_composite(demo_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70e7f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../artifacts/composite_score_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib, sklearn\n",
    "\n",
    "ARTIFACT_DIR = Path(\"../artifacts\")\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bundle_comp = {\n",
    "    \"pipe\": pipe_comp,\n",
    "    \"features\": FEATURES_COMP,\n",
    "    \"target\": \"composite_score\",\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_name\": \"composite_histgb_reg\",\n",
    "}\n",
    "\n",
    "out_path = ARTIFACT_DIR / \"composite_score_model.joblib\"\n",
    "joblib.dump(bundle_comp, out_path)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-zWdodsJX-py3.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
