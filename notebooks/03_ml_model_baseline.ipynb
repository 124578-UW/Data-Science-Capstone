{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src import config\n",
    "import src.optimization_utils as ou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520fe89",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load cleaned data from config path\n",
    "df = pd.read_csv(config.DATA_PROCESSED)\n",
    "df.columns = df.columns.astype(str).str.replace(\"\\n\",\" \").str.replace(r\"\\s+\",\" \", regex=True).str.strip()\n",
    "\n",
    "print(f\"Loaded {len(df)} patients, {df.shape[1]} columns\")\n",
    "print(f\"Data path: {config.DATA_PROCESSED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change data type to numeric for calculation\n",
    "df[[\"gap_score_preop\", \"gap_score_postop\"]]\\\n",
    "    = df[[\"gap_score_preop\", \"gap_score_postop\"]]\\\n",
    "        .apply(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
    "df[[\"ODI_preop\", \"ODI_12mo\"]]\\\n",
    "    = df[[\"ODI_preop\", \"ODI_12mo\"]]\\\n",
    "        .apply(pd.to_numeric, errors=\"coerce\").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae5688",
   "metadata": {},
   "source": [
    "### 1.1 Define input and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0195072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient preop fixed parameters\n",
    "PATIENT_FIXED_COLS = config.PATIENT_FIXED_COLS\n",
    "FEATURES = config.DELTA_MODEL_FEATURES.copy()\n",
    "\n",
    "print(\"== FEATURES ==\")\n",
    "for i in FEATURES:\n",
    "    print(i)\n",
    "\n",
    "FEATURES.remove(\"gap_score_preop\")\n",
    "FEATURES.remove(\"gap_category\")\n",
    "\n",
    "#from Hari's code\n",
    "NUMERIC_FEATURES = df[FEATURES].select_dtypes(\n",
    "    exclude=[\"object\", \"string\", \"category\"]\n",
    ").columns.tolist()\n",
    "\n",
    "CATEGORICAL_FEATURES = df[FEATURES].select_dtypes(\n",
    "    include=[\"object\", \"string\", \"category\"]\n",
    ").columns.tolist()\n",
    "\n",
    "print(\"\\n == Numerical Features (includes binary) ==\")\n",
    "for i in NUMERIC_FEATURES:\n",
    "    print(i)\n",
    "\n",
    "print(\"\\n == Categorical Features ==\")\n",
    "for i in CATEGORICAL_FEATURES:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"delta_L4S1\" not in df.columns:\n",
    "    df[\"delta_L4S1\"] = df[\"L4_S1_postop\"] - df[\"L4S1_preop\"]\n",
    "\n",
    "if \"delta_LL\" not in df.columns:\n",
    "    df[\"delta_LL\"] = df[\"LL_postop\"] - df[\"LL_preop\"]\n",
    "\n",
    "if \"delta_T4PA\" not in df.columns:\n",
    "    df[\"delta_T4PA\"] = df[\"T4PA_postop\"] - df[\"T4PA_preop\"]\n",
    "\n",
    "if \"delta_L1PA\" not in df.columns:\n",
    "    df[\"delta_L1PA\"] = df[\"L1PA_postop\"] - df[\"L1PA_preop\"]\n",
    "\n",
    "if \"delta_ODI\" not in df.columns:\n",
    "    df[\"delta_ODI\"] = df[\"ODI_12mo\"] - df[\"ODI_preop\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9c8cc",
   "metadata": {},
   "source": [
    "### 2. Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, PredictionErrorDisplay, make_scorer\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b218082",
   "metadata": {},
   "source": [
    "### 2.1 Set up for model building and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as Hari's\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "    )\n",
    "\n",
    "ridge_numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "           (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "#same as Hari's\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  \n",
    "           (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")) \n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Transform heterogeneous data types; same as Hari's\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, NUMERIC_FEATURES),\n",
    "        (\"cat\", categorical_transformer, CATEGORICAL_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "ridge_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", ridge_numeric_transformer,  NUMERIC_FEATURES),\n",
    "        (\"cat\", categorical_transformer, CATEGORICAL_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bbf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf_model(target_col, model_name):\n",
    "    \"Builds and fits a Random Forest model using a pipeline\"\n",
    "\n",
    "    data = df[FEATURES + [target_col]].dropna(subset=[target_col])\n",
    "\n",
    "    X = data[FEATURES]\n",
    "    y = data[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=300, \n",
    "                                            random_state=42,\n",
    "                                            max_depth=8,\n",
    "                                            min_samples_leaf=5,\n",
    "                                            oob_score=True)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", clone(preprocessor)), \n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    oob = pipe.named_steps[\"regressor\"].oob_score_\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "\n",
    "    print(f\"R² score: {round(r2,3)}\")\n",
    "    print(f\"RMSE: {round(rmse,3)}\")\n",
    "    print(f\"MAE: {round(mae, 3)}\")\n",
    "    print(f\"OOB score: {round(oob,3)}\")\n",
    "\n",
    "    return pipe, X_train, X_test, y_train, y_test, preds\n",
    "\n",
    "def train_ridge_model(target_col, model_name,alpha=1):\n",
    "    \"Builds and fits a Ridge Regression model within a pipeline\"\n",
    "\n",
    "    data = df[FEATURES + [target_col]].dropna(subset=[target_col])\n",
    "\n",
    "    X = data[FEATURES]\n",
    "    y = data[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", clone(ridge_preprocessor)),\n",
    "        (\"regressor\", Ridge(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test,preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "\n",
    "    print(f\"R² score: {round(r2,3)}\")\n",
    "    print(f\"RMSE: {round(rmse,3)}\")\n",
    "    print(f\"MAE: {round(mae, 3)}\")\n",
    "\n",
    "    return pipe, X_train, X_test, y_train, y_test, preds    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb14c5",
   "metadata": {},
   "source": [
    "### 3. Model Evaluation \n",
    "#### 3.1 Model 1: L4S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L4S1_model, X_train_L4S1, X_test_L4S1, y_train_L4S1, y_test_L4S1, y_pred_L4S1 = train_ridge_model(\"delta_L4S1\", \"ΔL4S1 Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a20b7",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"L4S1 Ridge Regression Model: Actual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_L4S1, \n",
    "    y_pred=y_pred_L4S1, \n",
    "    kind=\"actual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "#residual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"L4S1 Ridge Regression Model: Residual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_L4S1, \n",
    "    y_pred=y_pred_L4S1, \n",
    "    kind=\"residual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#residual histogram\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"L4S1 Ridge Regression Model: Residual Histogram\")\n",
    "\n",
    "L4S1_residuals = y_test_L4S1 - y_pred_L4S1\n",
    "sns.histplot(x=L4S1_residuals, kde=True, ax=ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1631f2",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_transformed = L4S1_model.named_steps[\"preprocessor\"].transform(X_test_L4S1)\n",
    "feature_names = L4S1_model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "explainer = shap.LinearExplainer(\n",
    "    L4S1_model.named_steps[\"regressor\"],\n",
    "    L4S1_model.named_steps[\"preprocessor\"].transform(X_train_L4S1),\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap_values = explainer(X_test_transformed)\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31611414",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec3da6",
   "metadata": {},
   "source": [
    "#### 3.2 Model 2: LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010df10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_model, X_train_LL, X_test_LL, y_train_LL, y_test_LL, y_pred_LL= train_rf_model(\"delta_LL\", \"ΔLL Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80cf93",
   "metadata": {},
   "source": [
    "#### Visualization of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e726c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"LL Random Forest Model: Actual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_LL, \n",
    "    y_pred=y_pred_LL, \n",
    "    kind=\"actual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "#residual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"LL Random Forest Model: Residual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_LL, \n",
    "    y_pred=y_pred_LL, \n",
    "    kind=\"residual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#residual histogram\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"LL Random Forest Model: Residual Histogram\")\n",
    "\n",
    "LL_residuals = y_test_LL - y_pred_LL\n",
    "sns.histplot(x=LL_residuals, kde=True, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f12d2d",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3523865",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = LL_model.named_steps[\"preprocessor\"].transform(X_test_LL)\n",
    "feature_names = LL_model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "explainer = shap.LinearExplainer(\n",
    "    LL_model.named_steps[\"regressor\"],\n",
    "    LL_model.named_steps[\"preprocessor\"].transform(X_train_LL),\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap_values = explainer(X_test_transformed)\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, plot_type=\"bar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9ee9b",
   "metadata": {},
   "source": [
    "### 3.3 Model 3:T4PA Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b87e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "T4PA_model, X_train_T4PA,X_test_T4PA, y_train_T4PA, y_test_T4PA, y_pred_T4PA = train_ridge_model(\"delta_T4PA\", \"ΔT4PA Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce372cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"T4PA Ridge Regression Model: Actual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_T4PA, \n",
    "    y_pred=y_pred_T4PA, \n",
    "    kind=\"actual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "#residual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"T4PA Ridge Regression Model: Residual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_T4PA, \n",
    "    y_pred=y_pred_T4PA, \n",
    "    kind=\"residual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#residual histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"T4PA Ridge Regression Model: Residual Histogram\")\n",
    "\n",
    "T4PA_residuals = y_test_T4PA - y_pred_T4PA\n",
    "sns.histplot(x=T4PA_residuals, kde=True, ax=ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc1b66",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = T4PA_model.named_steps[\"preprocessor\"].transform(X_test_T4PA)\n",
    "feature_names = T4PA_model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "explainer = shap.LinearExplainer(\n",
    "    T4PA_model.named_steps[\"regressor\"],\n",
    "    T4PA_model.named_steps[\"preprocessor\"].transform(X_train_T4PA),\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap_values = explainer(X_test_transformed)\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660dce9",
   "metadata": {},
   "source": [
    "### 3.4 Model 4:L1PA Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1PA_model, X_train_L1PA,X_test_L1PA, y_train_L1PA,y_test_L1PA, y_pred_L1PA = train_ridge_model(\"delta_L1PA\", \"ΔL1PA Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"L1PA Ridge Regression Model: Actual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_L1PA, \n",
    "    y_pred=y_pred_L1PA, \n",
    "    kind=\"actual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "#residual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"L1PA Ridge Regression Model: Residual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_L1PA, \n",
    "    y_pred=y_pred_L1PA, \n",
    "    kind=\"residual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#residual histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"L1PA Ridge Regression Model: Residual Histogram\")\n",
    "\n",
    "L1PA_residuals = y_test_L1PA - y_pred_L1PA\n",
    "sns.histplot(x=L1PA_residuals, kde=True, ax=ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873529f4",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = L1PA_model.named_steps[\"preprocessor\"].transform(X_test_L1PA)\n",
    "feature_names = L1PA_model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "explainer = shap.LinearExplainer(\n",
    "    L1PA_model.named_steps[\"regressor\"],\n",
    "    L1PA_model.named_steps[\"preprocessor\"].transform(X_train_L1PA),\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap_values = explainer(X_test_transformed)\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a854de",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd96cb7",
   "metadata": {},
   "source": [
    "#### 3.5 MODEL 5: ODI After 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3191c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ODI_model, X_train_ODI,X_test_ODI,y_train_ODI,y_test_ODI, y_pred_ODI = train_ridge_model(\"delta_ODI\", \"ΔODI Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14904cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"ODI Ridge Regression Model: Actual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_ODI, \n",
    "    y_pred=y_pred_ODI, \n",
    "    kind=\"actual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "#residual vs predicted plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"ODI Ridge Regression Model: Residual vs Predicted\")\n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_true=y_test_ODI, \n",
    "    y_pred=y_pred_ODI, \n",
    "    kind=\"residual_vs_predicted\", \n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    "    ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#residual histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"ODI Ridge Regression Model: Residual Histogram\")\n",
    "\n",
    "ODI_residuals = y_test_ODI - y_pred_ODI\n",
    "sns.histplot(x=ODI_residuals, kde=True, ax=ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b5a29",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = ODI_model.named_steps[\"preprocessor\"].transform(X_test_ODI)\n",
    "feature_names = ODI_model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "explainer = shap.LinearExplainer(\n",
    "    ODI_model.named_steps[\"regressor\"],\n",
    "    ODI_model.named_steps[\"preprocessor\"].transform(X_train_ODI),\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap_values = explainer(X_test_transformed)\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eca6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca53d5",
   "metadata": {},
   "source": [
    "### 4. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12457327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_rf_model(target_col):\n",
    "    data = df[FEATURES + [target_col]].dropna(subset=[target_col])\n",
    "\n",
    "    X = data[FEATURES]\n",
    "    y = data[target_col]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=300, \n",
    "                                            random_state=42,\n",
    "                                            max_depth=8,\n",
    "                                            min_samples_leaf=5,\n",
    "                                            oob_score=True)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", clone(preprocessor)), \n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    return pipe\n",
    "\n",
    "def final_ridge_model(target_col, alpha=1):\n",
    "    data = df[FEATURES + [target_col]].dropna(subset=[target_col])\n",
    "\n",
    "    X = data[FEATURES]\n",
    "    y = data[target_col]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", clone(ridge_preprocessor)),\n",
    "        (\"regressor\", Ridge(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final model for deployment - L4S1 ridge regression \n",
    "L4S1_pipe = final_ridge_model(\"delta_L4S1\")\n",
    "L4S1_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de730dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final model for deployment - LL random forest\n",
    "\n",
    "LL_pipe = final_rf_model(\"delta_LL\")\n",
    "LL_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebe88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final model for deployment - T4PA ridge regression\n",
    "T4PA_pipe = final_ridge_model(\"delta_T4PA\")\n",
    "T4PA_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53735b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final model for deployment - L1PA ridge regression\n",
    "L1PA_pipe = final_ridge_model(\"delta_L1PA\")\n",
    "L1PA_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa55974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final model for deployment - ODI ridge regression\n",
    "ODI_pipe = final_ridge_model(\"delta_L1PA\")\n",
    "ODI_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ce731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, sklearn\n",
    "from src import config\n",
    "\n",
    "# L4S1 model\n",
    "L4S1_dir = config.ARTIFACTS_DIR / \"L4S1\"\n",
    "L4S1_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bundle_L4S1 = {\n",
    "    \"pipe\": L4S1_pipe,\n",
    "    \"features\": FEATURES,\n",
    "    \"target\": \"delta_L4S1\",\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_name\": \"RidgeRegressor_delta_L4S1\"\n",
    "}\n",
    "out_path = L4S1_dir / \"delta_L4S1_model.joblib\"\n",
    "joblib.dump(bundle_L4S1, out_path)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# LL model\n",
    "LL_dir = config.ARTIFACTS_DIR / \"LL\"\n",
    "LL_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bundle_LL = {\n",
    "    \"pipe\": LL_pipe,\n",
    "    \"features\": FEATURES,\n",
    "    \"target\": \"delta_LL\",\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_name\": \"RandomForest_delta_LL\",\n",
    "}\n",
    "\n",
    "out_path = LL_dir / \"delta_LL_model.joblib\"\n",
    "joblib.dump(bundle_LL, out_path)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# T4PA model\n",
    "T4PA_dir = config.ARTIFACTS_DIR / \"T4PA\"\n",
    "T4PA_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bundle_T4PA = {\n",
    "    \"pipe\": T4PA_pipe,\n",
    "    \"features\": FEATURES,\n",
    "    \"target\": \"delta_T4PA\",\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_name\": \"RidgeRegressor_delta_T4PA\",\n",
    "}\n",
    "\n",
    "out_path = T4PA_dir / \"delta_T4PA_model.joblib\"\n",
    "joblib.dump(bundle_T4PA, out_path)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# L1PA model\n",
    "L1PA_dir = config.ARTIFACTS_DIR / \"L1PA\"\n",
    "L1PA_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bundle_L1PA = {\n",
    "    \"pipe\": L1PA_pipe,\n",
    "    \"features\": FEATURES,\n",
    "    \"target\": \"delta_L1PA\",\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_name\": \"RidgeRegressor_delta_L1PA\",\n",
    "}\n",
    "\n",
    "out_path = L1PA_dir / \"delta_L1PA_model.joblib\"\n",
    "joblib.dump(bundle_L1PA, out_path)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# ODI model\n",
    "ODI_dir = config.ARTIFACTS_DIR / \"ODI\"\n",
    "ODI_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bundle_ODI = {\n",
    "    \"pipe\": ODI_pipe,\n",
    "    \"features\": FEATURES,\n",
    "    \"target\": \"delta_ODI\",\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_name\": \"RidgeRegressor_delta_ODI\",\n",
    "}\n",
    "\n",
    "out_path = ODI_dir / \"delta_ODI_model.joblib\"\n",
    "joblib.dump(bundle_ODI, out_path)\n",
    "print(\"Saved:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
